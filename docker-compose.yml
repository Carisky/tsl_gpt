# docker-compose.deploy.yml (v2 стиль)
name: tslgpt
services:
  db:
    image: postgres:16
    restart: unless-stopped
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: tslgpt
    ports:
      - "5434:5432"
    volumes:
      - db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 10

  backend:
    image: cariski/tslgpt-backend:latest
    working_dir: /usr/src/app
    restart: unless-stopped
    environment:
      PORT: 3300
      NODE_ENV: development
      DATABASE_URL: postgresql://postgres:postgres@db:5432/tslgpt?schema=public
      JWT_SECRET: supersecret_dev_key_change_me
      CORS_ORIGIN: http://localhost:3007,http://localhost:3007
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ALLOWED_MODELS: gpt-4o-mini,gpt-4o,gpt-4.1-mini,o3-mini
      DEFAULT_MODEL: gpt-4o-mini
      MOCK_AI: "true"
    ports: ["3307:3300"]
    depends_on: { db: { condition: service_healthy } }
    command: sh -c "npx prisma generate && npx prisma migrate deploy && npx prisma db push && npm run dev"
    volumes:
      - ./backend:/usr/src/app
      - /usr/src/app/node_modules

  frontend:
    image: cariski/tslgpt-frontend:latest
    working_dir: /usr/src/app
    restart: unless-stopped
    environment:
      NEXT_PUBLIC_API_URL: http://localhost:3307
      # Improve HMR reliability inside Docker on Windows/macOS
      CHOKIDAR_USEPOLLING: "true"
      WATCHPACK_POLLING: "true"
      WATCHPACK_POLLING_INTERVAL: 1000
      NEXT_WEBPACK_USEPOLLING: "1"
    ports: ["3007:3000"]
    depends_on: [backend]
    volumes:
      - ./frontend:/usr/src/app
      - /usr/src/app/node_modules
      - /usr/src/app/.next

volumes:
  db-data:
